COOPERNAUT：基于网联车辆协作感知的端到端驾驶



### 摘要

过去几年中，自动驾驶汽车的光学传感器和学习算法取得了巨大的进步。尽管如此，当今自动驾驶汽车的可靠性仍然受到视距（Line-of-sight）感知能力的限制，以及数据驱动方法在处理极端情况（extreme situations）时的脆弱性的阻碍。随着电信技术的最新发展，基于车对车（V2V）通信的协作感知已成为一种有前途的范式，可以增强危险或紧急情况下的自动驾驶能力。我们介绍了 **COOPERNAUT**，这是一种利用跨车辆感知进行基于视觉的协作驾驶的端到端学习模型。我们的模型将激光雷达（LiDAR）信息编码为紧凑的点基表示（point-based representations），这些表示可以通过现实的无线信道作为消息在车辆之间传输。为了评估我们的模型，我们开发了 **AUTOCASTSIM**，这是一个网络增强型驾驶仿真框架，其中包含易发生事故的示例场景。我们在 AUTOCASTSIM 上的实验表明，我们的协作感知驾驶模型在这些具有挑战性的驾驶情况下的平均成功率比以自车为中心的驾驶模型提高了 40%，并且带宽需求比之前的工作 V2VNet 小 5 倍。COOPERNAUT 和 AUTOCASTSIM 可在 https://ut-austin-rpl.github.io/Coopernaut/ 获取。



### 1. 引言

自动驾驶和高级驾驶辅助系统的广泛部署面临着安全问题的挑战。虽然深度学习通过数据驱动技术改进了自动驾驶技术栈，但迄今为止，基于学习的驾驶策略仍然很脆弱，特别是在面对极端情况和每百万英里驾驶中可能仅遇到几次的长尾案例（corner cases）时。由于单车光学传感器（如立体摄像头和激光雷达）的感知能力有限，这种学习算法缺乏鲁棒性的问题变得更加严重，这些传感器局限于视距感知，且在恶劣天气条件下不可靠。

随着新电信技术（如 5G 网络和车对车 (V2V) 通信）的出现，协作感知正成为一种有前途的范式，它使得传感器信息能够在车辆之间（以及路侧设备）实时共享。共享信息可以扩充单个车辆的视野，并传达附近车辆的意图和路径规划，从而具有提高驾驶安全性的潜力，特别是在易发生事故的场景中。

理想情况下，利用协作感知学习自动驾驶策略应利用现有的为单车感知定制的深度学习方法，将来自所有车辆的组合传感数据视为车载传感的增强版本。在实践中，协作感知的有效性取决于在有限的网络带宽内传输什么数据，以及如何使用聚合信息来建立对交通状况的一致且准确的理解。最近关于协作驾驶的工作已经证明了跨车辆感知在增强感知能力和驾驶决策方面的益处。尽管如此，这些方法已将原始传感数据抽象为低维元数据。先前的工作引入了 3D 传感器融合（AVR, Cooper）和表示融合（V2VNet）算法，通过 V2V 信道聚合来自附近车辆的感知结果。它们侧重于静态数据集上的 3D 检测和运动预测，而不是交互式驾驶策略。

我们介绍了 COOPERNAUT，这是一种用于网联车辆的端到端协作驾驶模型。COOPERNAUT 学习在现实的 V2V 信道容量下融合附近车辆共享的编码激光雷达信息。为了传达来自附近车辆的有意义的场景信息，同时符合带宽限制，我们基于 Point Transformer（一种用于点云处理的自注意力网络）设计了我们的驾驶策略架构。该架构在每个网联车辆本地预处理原始点云，将其转化为空间感知的神经表示。这些表示是紧凑的，可以通过现实的无线信道有效地传输。同时，它们是基于物理位置的，因此可以进行空间变换并与自车表示进行聚合。整个架构是端到端可微分的，允许控制监督（模仿拥有特权信息的预言机规划器）回流到感知栈，从而确保学习到的表示和消息包含与任务相关的信息。

为了检验 COOPERNAUT 的有效性，我们开发了一个基于 CARLA 的仿真框架 AUTOCASTSIM，并在其中设计了三个易发生事故的场景。所有场景都被设计为对单车感知完全理解交通状况具有挑战性。AUTOCASTSIM 具有内置的网络仿真，用于可定制的多车通信，以及一个拥有特权信息的专家驾驶模型。我们将 COOPERNAUT 与基于体素的基线模型以及不同的传感器融合方案进行了评估。

总之，我们的主要贡献如下：
* 我们介绍了 COOPERNAUT，这是一种通过 V2V 信道进行协作感知的端到端驾驶模型。
* 我们的模型学习用于通信的紧凑表示，自车可以轻松利用这些表示来改进其驾驶决策。
* 我们开发了一个网络增强型自动驾驶仿真框架 AUTOCASTSIM，用于在易发生事故的场景中评估 COOPERNAUT 和基线模型，并促进未来关于基于视觉的协作感知研究。
* 我们的结果表明，COOPERNAUT 大幅减少了视距感知的安全隐患。其设计在驾驶性能和通信效率方面均优于基线模型。

### 2. 相关工作

**用于驾驶策略的深度学习。** 学习驾驶控制器涉及使用深度网络训练闭环策略，通常通过模仿学习和/或强化学习来实现。自动驾驶的模仿学习由 Pomerleau 开创，并自那时起已扩展到城市和更复杂的场景。最近，强化学习在自动驾驶方面也取得了进展，显示出在复杂情况训练更好策略的潜力。然而，众所周知，强化学习更依赖数据，并且需要设计高质量的奖励函数。我们遵循模仿学习范式，但为了训练效率，使用了一个拥有完整全局信息的专家预言机（oracle）。



**自动驾驶的 3D 感知。** 由于商品化激光雷达传感器成本的降低，3D 感知在自动驾驶中变得越来越流行。Zhou 和 Tuzel 开创了在自动驾驶中使用 3D 物体检测的先河，自那时起，它已被进一步开发为更好的模型，并发现了更先进的技术。最近，Prakash 等人也探索了使用点云数据进行端到端驾驶。两类 3D 感知主干网络已被广泛采用：基于体素的方法将点离散化为体素；基于点的方法直接在坐标上操作。COOPERNAUT 使用基于 Transformer 的架构和基于点的表示，这保留了高空间分辨率与离散化，并且传输时需要的带宽较低，无需像先前工作那样进行压缩。



**网联车辆与协作感知。** 网络连接为提高自动驾驶汽车的安全性和可靠性提供了巨大的潜力。车辆现在可以使用无线技术（如专用短程通信 (DSRC) 和蜂窝辅助 V2X (C-V2X)）通过车对车 (V2V) 和车对基础设施 (V2X) 信道共享周围信息。这些 V2V/V2X 通信设备正越来越多地部署在当前和即将推出的车型中。学术界已经建立了城市规模的无线研究平台（COSMOS）和大型联网车辆测试台（例如 MCity, DRIVE C2X），以探索协作车辆和应用的可行性。先前的工作提出了协作感知系统，通过与附近其他车辆共享原始视觉信息来拓宽车辆的视野。此类系统可以利用边缘服务器扩展到密集的交通场景，或者以自组织的方式进行。最近的工作提出了多智能体感知模型，以处理传感器信息并在本地交通网络内共享紧凑的表示。相比之下，我们专注于具有车载视觉数据和现实网络条件的网联车辆的协作驾驶，向现实世界的 V2V 设置迈进。



### 3. COOPERNAUT

#### 3.1. 问题陈述

我们的目标是学习一个闭环策略来控制一辆自动驾驶自车（ego vehicle），该车辆在时间 $t$ 接收激光雷达观测值 $O_{t}^{(ego)}$。假设在时间 $t$ 有 $N_{t}$ 辆相邻车辆处于 V2V 通信范围内，其中 $O_{t}^{(i)}$ 是第 $i$ 辆车车载激光雷达的原始 3D 点云。自车的协作驾驶策略是找到一个策略 $\pi(a_{t}|O_{t}^{(ego)},O_{t}^{(1)},...,O_{t}^{(N_{t})})$，该策略基于自车和 $N_{t}$ 辆相邻车辆的联合观测值做出控制决策 $a_{t}$。这里由深度神经网络参数化并进行端到端训练。原则上，我们可以将所有跨车辆观测值传输给自车并作为一个整体进行处理。实际上，我们必须考虑到网络带宽限制，这只允许消息大小小几个数量级。因此，我们首先将原始点云处理成紧凑的表示，这些表示可以通过 V2V 信道实时传输。



#### 3.2. 背景：Point Transformer

我们模型的主干是 Point Transformer，这是一种新开发的神经网络结构，可以从 3D 点云中学习紧凑的基于点的表示。它推理点之间的非局部相互作用并生成置换不变（permutation-invariant）的表示，使其能够有效地聚合多车点云。这里我们简要回顾一下 Point Transformers。

我们采用与 Zhao 等人相同的设计，使用向量自注意力来构建 Point Transformer 层。我们还在特征之间应用减法，并将位置编码函数 $\delta$ 附加到注意力向量 $\gamma$ 和变换后的特征 $\alpha$ 上：
$$
y_{i}=\sum_{x_{j}\in\mathcal{X}(i)}\rho(\gamma(\phi(x_{i})-\psi(x_{j})+\delta))\odot(\alpha(x_{j})+\delta) \tag{1}
$$
这里 $x_{i}$ 和 $x_{j}$ 分别是点 $i$ 和 $j$ 的输入特征，$y_{i}$ 是点 $i$ 的输出注意力特征，$\mathcal{X}(i)$ 代表 $x_{i}$ 邻域内的点集；$\phi,\psi$ 和 $\alpha$ 是逐点特征变换（MLP）；$\gamma$ 是一个具有两层和一个 ReLU 非线性的 MLP 映射函数；$\delta$ 是位置编码函数，$\rho$ 是归一化函数 softmax。给定点 $i$ 和 $j$ 的 3D 坐标 $p_{i}, p_{j}\in\mathbb{R}^{3}$，位置编码函数公式如下：
$$
\delta=\theta(p_{i}-p_{j}) \tag{2}
$$
其中 $\theta$ 是一个具有两个线性层和一个 ReLU 的 MLP。

Point Transformer 块如图 2 所示，它集成了自注意力层、线性投影和残差连接。输入是一组 3D 点 $p$ 以及每个点的特征 $x$。该块使得点之间能够进行局部信息交换，并为每个点生成新的特征向量。图 2 中的下采样块用于减少点集的基数。我们对输入集执行最远点采样 (Farthest Point Sampling) 以获得分布良好的子集，然后使用 kNN 图和邻域内的（局部）最大池化将信息进一步压缩到更小的点集。输出是具有新特征的原始输入点的子集。



#### 3.3. 我们的模型

我们使用跨车辆感知来增强自车的传感能力，使其能够在具有挑战性的情况下做出更明智的决定。关键挑战在于通过现实的 V2V 信道有效地传输传感信息，从聚合信息中理解交通状况，并实时确定反应性驾驶动作。

我们的 COOPERNAUT 模型（如图 2 所示）由以下部分组成：用于每辆相邻 V2V 车辆的 **Point Encoder（点编码器）**，用于将其传感数据编码为紧凑消息；**Representation Aggregator（表示聚合器）**，用于将来自相邻车辆的消息与自车感知进行整合；以及 **Control Module（控制模块）**，用于将整合后的表示转化为驾驶命令。

**Point Encoder（点编码器）。** 为了减少通信负担，每辆 V2V 车辆在本地处理其自己的 LiDAR 数据，并将原始 3D 点云编码为关键点（keypoints），每个关键点都与 Point Transformer 块学习到的紧凑表示相关联。我们用三个 Point Transformer 块伴随两个下采样块构建编码器，下采样率均为 (1, 4, 4)。中间表示的最终基数为 $P/16$，其中 $P$ 是原始点云中的点数。在我们的实验中，我们通过体素池化（即使用体素质心表示体素网格中的点）将 65,536 个原始 LiDAR 点预处理为 2,048 个点。
第 $j$ 辆车产生的消息 $M_{j}$ 包含一组基于位置的表示，数学描述为 $M_{j}=\{(p_{jk},R_{p_{jk}})\}^{K}$，其中 $p_{jk}\in\mathbb{R}^{3}$ ($k=1,...,K$) 是 3D 空间中关键点的位置，$R_{p_{jk}}$ 是 Point Encoder 产生的对应特征向量。我们将 $M_{j}$ 的大小限制为最多 $K$ 个元组。这些携带特征的关键点位于每辆车的局部坐标系中。由于它们的坐标是从原始点云中采样的，因此保留了空间信息。

**Representation Aggregator（表示聚合器）。** 从其他车辆传输的消息需要由自车进行融合和解释。用于协作感知的表示聚合器 (RA) 实现为体素最大池化操作和一个 Point Transformer 块。RA 首先利用相对位姿将其他车辆坐标系中的关键点空间变换到自车的坐标系中。此操作假设有精确的车辆定位（例如，使用高精地图）。然后，它通过最大池化位于同一体素网格单元内的所有点，来聚合空间上接近的传入消息。最后，它使用另一个 Point Transformer 块融合多视角感知信息。上述两个操作保留了关于其他车辆顺序的置换不变性，并且可以处理可变数量的共享车辆。为了控制带宽，COOPERNAUT 从附近随机选择的三辆 V2V 车辆接收消息。

**Control Module（控制模块）。** 控制模块是一个全连接神经网络，旨在根据接收到的消息做出控制决策。这些控制决策包括油门、刹车和转向，分别表示为标量 T, B, S。从模型输出的这些值首先被裁剪到其有效范围（例如，油门为 [0,1]）。为了遵守速度限制规则，我们应用 PID 速度控制器来防止超速。



#### 3.4. 策略学习

我们使用 DAgger 训练我们的模型，以模仿利用特权信息的专家策略。为了预热策略学习，我们首先使用行为克隆（Behavior Cloning）来训练模型。 

**行为克隆** (Behavior Cloning) ：行为克隆旨在最小化训练策略与专家策略之间的分布差异。其目标是找到一个最优策略 $\hat{\pi}$，使得在专家策略 $\pi_{expert}$ 所诱导的状态分布 $S^*$ 下的损失最小化。

 
$$
\hat{\pi} = \mathop{\arg\min}_{\pi} \mathbb{E}_{s \sim S^*} [l_{control} (\pi(s), \pi_{expert}(s))] \quad  \tag{3}
$$
目标函数 $l_{control}$ 是策略动作与专家动作之间油门、刹车和转向的 $L_1$-Loss 的线性组合：
$$
l_{control}=\eta_{1}l_{throttle}+\eta_{2}l_{brake}+\eta_{3}l_{steer} \tag{4}
$$
其中 $\eta_{1}, \eta_{2}, \eta_{3}$​ 是每个动作损失的系数。在我们的实验中，所有三个系数都设置为 1。

**DAgger。** Codevilla 等人讨论了行为克隆在自动驾驶中的局限性。DAgger 通过在线训练解决了协变量偏移（covariance shift）问题。核心思想是让学生策略与环境互动，并在专家监督下记录专家在学生访问的相同状态下的动作。训练数据集是迭代聚合的，使用学生和专家动作的混合。第 $i$ 次迭代的采样策略 $\pi_{sample,i}$ 如下：
$$
\pi_{sample,i} = \begin{cases}
\pi_{expert}, & \text{w.p. } \beta_{i} \\
\pi_{student}, & \text{w.p. } 1-\beta_{i}
\end{cases}

\tag{5}
$$
其中 $\beta_{i}=\beta_{0}\times\beta_{i-1}^{i}$ 是从初始 $\beta_{0}$ 指数递减的，代表在第 $i$ 次迭代中执行专家动作的概率。



#### 3.5. 实现细节

当超过三辆相邻车辆发送消息时，我们随机选择其中三辆车的消息。所有邻居都通过 3 块 Point Encoder 在本地编码其处理后的点云，并发送大小为 $128\times(128,3)$ 的消息，并将坐标变换到自车坐标系。我们通过另一块 Point Transformer 聚合合并后的表示。经过全局最大池化后，特征在传递给全连接层之前与自车速度特征连接。
我们的模型在 NVIDIA GTX3090 GPU 上具有 90ms 的延迟，其中点编码器耗时 80ms。我们的模型训练包括两个阶段：行为克隆和 DAgger。我们首先通过行为克隆训练每个特定场景的模型，然后行为克隆的最终策略作为 DAgger 的初始学生策略。在 DAgger 阶段，我们每 5 个 epoch 使用 $\beta_{0}=0.8$ 的采样策略（见 §3.4）收集 4 条新轨迹并将其附加到 DAgger 数据集。对于所有用于训练的数据，25% 是在易发生事故的场景（插入了被遮挡的碰撞车辆）下收集的，75% 是正常驾驶轨迹。更多详细信息，请参阅我们的补充材料和项目网站。



### 4. AUTOCASTSIM

我们提出了 AUTOCASTSIM，这是一个基于 CARLA 的仿真框架，提供网络增强型自动驾驶仿真。该仿真框架允许自定义设计各种交通场景，用于训练和评估协作驾驶模型。仿真车辆可以配置现实的无线通信。它还提供了一个基于路径规划的预言机专家，可以访问特权环境信息。



#### 4.1. 场景

我们在 AUTOCASTSIM 中设计了三个具有挑战性的交通场景（如图 3 所示）作为我们的评估基准。这些场景选自美国国家公路交通安全管理局 (NHTSA) 的碰撞前类型学，其中受限的视距传感会影响驾驶决策：

* **Overtaking（超车）。** 一辆卡车在双向单车道道路上挡住了一辆轿车的路，道路中间有黄色虚线分隔符。卡车还阻碍了轿车观察对面车道的视线。自车必须通过变道机动进行超车。
* **Left Turn（左转）。** 自车试图在左转让行灯处左转，但在对面的左转车道遇到另一辆卡车，阻挡了其观察对面车道和潜在直行车辆的视线。
* **Red Light Violation（闯红灯）。** 自车正在穿过十字路口，此时另一辆车正在闯红灯。由于排队等待左转的车辆，激光雷达无法感知到这辆车。



#### 4.2. V2V 通信

为了模拟现实的无线通信，我们使用真实的 V2V 无线电来分析由于移动代理之间的信道多样性导致的无线带宽容量和丢包率。具体来说，我们使用三个安装在移动车辆顶部的 iSmartways DSRC 无线电和三个 C-V2X 无线电，来测量实践中连续无线传输的最大容量。表 1 显示了测试的吞吐量和丢包率。为了便于参考，它还显示了 WiFi (802.11n, ac) 的吞吐量。请注意，802.11 系列并非为移动场景设计。表 1 显示 V2V 带宽比室内无线容量小两个数量级。极有限的带宽在实践中给 V2V 通信的表示设计带来了重大挑战。

我们在模拟器中使用 Winner II 无线信道模型，并在信道模型中使用测得的 C-V2X 无线电容量和丢包率。我们参考先前的工作以了解协调、调度和网络传输层的设计和实现。



#### 4.3. 预言机专家（Oracle Expert）

专家可以访问交通场景的特权信息。这些信息包括所有相邻车辆的激光雷达点云，以及这些相邻车辆和其他交通参与者的位置和速度。专家将所有来自相邻汽车的点云转换到其自车视角（由于上述无线带宽限制，这在实际中是不切实际的）。转换后的点云被融合用于下游障碍物检测和规划。专家策略利用上述所有信息来分析并避免可能的碰撞。路径规划算法使用带有位姿和距离启发式的 $A^{*}$ 轨迹规划器。专家以 20km/h 的目标速度移动。



### 5. 实验

我们首先讨论评估方法和实验设置，然后简要概述我们的基线模型。接下来，我们将展示我们的方法与基线模型的主要定量评估结果。最后，我们提供进一步的分析和可视化，以理解我们学习到的模型的质量。



#### 5.1. 实验设置

**场景配置。** 我们从在 AUTOCASTSIM 中实现的三个场景（§4.1）生成轨迹用于训练和评估。这些场景可以通过关键参数进行程序化重新配置，特别是车辆数量、车辆生成位置和车辆巡航速度。随机组合这些参数进行采样，以程序化生成具有不同复杂度的交通状况轨迹——在某些情况下，自车必须采取紧急行动以避免潜在碰撞，而在其他情况下，沿着默认路线巡航即可到达目的地。

**数据集。** 具体来说，对于每个场景，我们使用专家代理（§4.3）生成包含随机场景配置的 12 条轨迹作为初始训练集，随后为 DAgger 生成另外 84 条随机配置的轨迹。在评估中，我们系统地在 27 种随机选择的易发生事故的环境配置范围内测试每个模型，重复运行三次，每次使用不同的背景交通随机种子。为了公平比较，我们使用一组固定的 27 种测试配置来评估所有模型。

**指标。** 我们报告三个指标：成功率、碰撞率和加权完成时间的成功率：
* **Success Rate (SR，成功率)。** 场景的成功完成定义为自车在允许的时间内到达指定的目标位置，且没有碰撞或长时间停滞。成功率定义为所有评估轨迹中成功完成的百分比。
* **Collision Rate (CR，碰撞率)。** 碰撞是最常见的失败模式。碰撞率定义为自车与任何实体（如车辆、建筑物等）发生碰撞的评估轨迹的百分比。
* **Success weighted by Completion Time (SCT，加权完成时间的成功率)。** SR 反映了整体任务的成功或失败。它不区分驾驶代理完成轨迹所需的时间量。我们引入第三个指标，通过专家和代理之间的完成时间比率来加权成功率：
    $$SCT = I\{\text{agent success}\} \frac{T_{expert}}{T_{agent}}$$
    (6)
    其中 $I$ 是指示函数，$T_{expert}$ 和 $T_{agent}$ 分别是专家和代理的完成时间。由于专家代理所需的完成时间不应长于代理，该比率处于 [0, 1] 范围内。



#### 5.2. 基线模型

我们将 COOPERNAUT 与非 V2V 和 V2V 驾驶基线进行比较。为了公平比较，我们在 V2V 方法中采用相同的邻居选择过程（§3.5）：

* **No V2V Sharing（无 V2V 共享）。** 非共享基线仅根据车载激光雷达数据和自车速度做出决策。该模型与我们的最终模型共享相同的单车数据处理方案和点编码器架构。
* **Early Fusion（早期融合）。** 早期融合模型假设不切实际的通信带宽，使其能够传输和融合来自所有相邻车辆的完整原始点云数据。虽然这种方法在实践中难以实现，但它作为一个基线来检查我们的点基架构在表示学习方面的有效性。为了使该模型适应 GPU 内存，我们将融合输入点的大小限制为 4,096。像前一个基线一样，早期融合也使用 3 块 Point Transformer 编码器。
* **Voxel GNN（体素 GNN）。** 我们改编了 V2VNet，其原本设计用于 3D 检测和运动预测，用于学习端到端驾驶。每辆车在车载处理其本地点云，并与自车共享体素表示以进行控制。它在自车坐标系中使用图神经网络 (GNN) 作为聚合器。控制动作是根据 GNN 融合的表示预测的。

为了公平比较，所有基线和提出的方法都在三次重复运行中独立训练，并使用相同的训练参数（§3.5）。我们报告这三次运行在相同场景配置下的平均性能（§5.1）。



#### 5.3. 定量结果

本节展示了所有模型在三个基准场景中的实证评估。

**场景完成情况。** 表 2 显示了三个交通场景中的性能比较。在所有三个场景中，**No V2V Sharing** 模型的表现都很差，每个场景的成功率都低于 50%，且碰撞率很高。所有三个协作驾驶模型，包括 **Early Fusion**、**Voxel GNN** 和 **COOPERNAUT**，都取得了比 No V2V Sharing 基线高得多的 SR 和 SCT 分数以及更低的碰撞率。这表明 V2V 通信提供了比自车视距传感更关键的交通状况信息，以做出明智的驾驶决策。Early Fusion 方法在平均成功率上比非 V2V 基线提高了 30% 以上。然而，Early Fusion 基线需要跨车辆传输原始点云，导致了 60Mbps 的不切实际的带宽需求（数据压缩前）。
相比之下，将原始传感数据预处理为表示形式显著降低了带宽需求，同时提高了驾驶性能。Voxel GNN 和 COOPERNAUT 都在表示层面上进行传感器融合。与其他协作驾驶模型相比，COOPERNAUT 在所有三个场景中都优于 Early Fusion 和 Voxel GNN 基线。我们假设 COOPERNAUT 的基于点的表示学习使其在面对定位误差时比融合原始点的 Early Fusion 更鲁棒。此外，与 Voxel GNN 使用的基于体素的特征图相比，COOPERNAUT 的点 3D 位置的显式表示和点采样模块保留了其中间表示的高空间分辨率。

**带宽需求。** 如表 2 所示，以 10fps 的激光雷达扫描速率共享原始点云将需要 60Mbps 的无线带宽，这远远超出了当前 (DSRC) 和未来 (C-V2X 或 LTE-direct) V2V 通信技术可实现的带宽（预期小于 10Mbps，见表 1）。V2VNet 声称在使用点云压缩的情况下带宽需求为 25 Mbps，这也超出了当前 V2V 无线电所能支持的范围。
在我们的设计中，Voxel GNN 和 COOPERNAUT 需要的带宽都小于 6Mbps，这是 V2VNet 无压缩通信数据量的 4 倍缩减。在开发 V2V 模型时，我们仔细探索了 Voxel GNN 和 COOPERNAUT 的可共享表示大小及其带宽需求的设计空间。例如，如果 COOPERNAUT 共享 $32\times32$ 的表示，它只需要 0.9 Mbps。然而，粗糙的信息不足以使模型获得良好的性能。我们发现 $128\times128$ 的点表示满足带宽要求（表 1），且没有显著的性能下降。

**对交通密度的敏感性。** 我们在最具挑战性的左转场景中，在不同的交通密度下进一步测试 COOPERNAUT。图 4 显示我们的方法可以推广到可变的交通密度，始终优于 No V2V Sharing 基线。定性地，我们观察到 No V2V Sharing 在更密集的交通中驾驶得更慢，对紧急情况的反应更好。相比之下，V2V 方法在更密集的交通中并没有太大改善，因为它们往往受到来自不断变化的邻居的传入消息增加的随机性的影响。尽管如此，COOPERNAUT 在所有交通密度下都优于基线，成功率比 No V2V Sharing 高出 30% 以上。

**定性可视化。** 图 5 展示了左转场景中的一个评估轨迹示例。左转的自车（灰色）可以通过 COOPERNAUT 主动避让对面来车从而避免碰撞。非共享模型的一个常见失败模式是，由于其自车感知的视距有限，它会不顾任何交通违规者或潜在碰撞者，径直驶向其目标位置。通过 V2V 信道传输的消息帮助我们的模型利用跨车辆感知解决模糊性，从而在这种易发生事故的情况下做出更安全的驾驶决策。



#### 5.4. 局限性与未来工作

虽然我们的协作感知模型符合现实的无线带宽，但我们没有考虑实际的网络问题，包括传输延迟、网络协议以及重复或丢失的数据包。尽管如此，COOPERNAUT 在一定程度上（如 AUTOCASTSIM 中配置的 5%）对丢包具有鲁棒性。其随机邻居选择也增加了另一层保障，以承受来自单个发射器的丢包。

此外，COOPERNAUT 假设了高精度的车辆定位，用于将基于点的表示从相邻车辆转换到自车，即使 AUTOCASTSIM 模拟了车辆位姿和高度估计的轻微误差。在现实中，如果没有高精地图 (HDMap)，定位误差可能会产生米级的位移。使用 HDMap 可以显著提高位置和位姿估计，这在工业界和学术界都被普遍采用。

为了公平比较，我们对所有基于点的基线和我们的方法使用相同的下采样方案，这在我们的移动车辆和大型障碍物场景中被证明是有效的。对于像行人这样的较小物体，基于语义信息的自适应采样方案是未来工作的一个有前途的方向。我们还希望扩展 COOPERNAUT 的模型架构，以更好地结合时间信息来提高驾驶性能。



### 6. 结论与未来工作

这项工作在重新设计的仿真基准 AUTOCASTSIM 中研究了网联车辆使用协作感知的基于视觉的驾驶。我们介绍了 COOPERNAUT，这是一种端到端的驾驶策略，用于编码、聚合和分析来自网联车辆的 3D LiDAR 数据。COOPERNAUT 的点编码器和表示聚合器保留了详细的空间信息，并对通信车辆数量的变化具有鲁棒性。我们的实证结果表明，我们的方法提高了自动驾驶策略在风险敏感交通场景中的鲁棒性。

这项工作有很大的未来扩展空间。我们的方法依赖于人工设计的预言机进行模仿学习。它留下了开放性问题，即研究何时通信、在消息中编码什么以及如何协作驾驶的自适应策略，理想情况下无需算法预言机。

