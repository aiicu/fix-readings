Who2com：通过可学习的握手通信实现协同感知

**Yen-Cheng Liu, Junjiao Tian, Chih-Yao Ma, Nathan Glaser, Chia-Wen Kuo and Zsolt Kira**
Georgia Institute of Technology
{ycliu, jtian73, cyma, nglaser3, albert.cwkuo, zkira}@gatech.edu



### 摘要

在本文中，我们提出了协同感知（collaborative perception）问题，即机器人可以以一种可学习的方式将其局部观测结果与邻近智能体的观测结果相结合，以提高感知任务的准确性。与机器人学和多智能体强化学习中的现有工作不同，我们将该问题表述为：为了优化诸如语义分割等场景理解任务，学习到的信息必须以带宽敏感（bandwidth-sensitive）的方式在一组智能体之间共享。受网络通信协议的启发，我们提出了一种多阶段握手通信机制，其中神经网络可以学习压缩每个阶段所需的相关信息。具体而言，具有受损传感器数据的目标智能体发送压缩请求，其他智能体以匹配分数进行响应，目标智能体决定与谁连接（即接收信息）。我们还基于 AirSim 模拟器开发了 AirSim-CP 数据集和指标，其中一组空中机器人感知不同的景观，如道路、草地、建筑物等。我们表明，对于语义分割任务，我们的握手通信方法比去中心化基线方法的准确性显著提高了约 20%，并且在使用四分之一带宽的情况下与中心化方法相当。

---

### I. 引言

利用深度神经网络在单智能体场景理解方面已经取得了巨大进展 [40, 12, 4]。然而，随着这些方法变得无处不在以及大量机器人被部署到现实世界中，通过通信共享知识变得十分有益。例如，在一队自动驾驶汽车之间共享知识可以缓解诸如遮挡以及传感器退化或故障等挑战。

在本文中，我们提出了协同感知问题，即机器人可以将其局部观测与邻近智能体的观测相结合，以提高感知任务（如语义分割 [23, 3]）的准确性。这可以带来显著的改进，例如当接收智能体的传感器被遮挡或退化时（见图 1）。因此，我们要构建一个问题，即一个受损智能体（degraded agent）可以与其他智能体通信以提高其感知能力。与过去专注于多机器人定位和建图的方法 [6, 32] 不同，我们开发的智能体能够以一种适合端到端深度学习（目前在场景理解中占主导地位）的方式学习“通信什么内容”。此外，与多智能体强化学习 [36, 2, 10, 29, 17, 30, 9] 不同，我们要寻求在带宽约束下实现这一点。

因此，我们建议学习“与谁通信”，以便在提高准确性的同时降低带宽需求。这种方法对于具有子模性（sub-modularity property）的标准观测问题是有效的，即增加更多的观测智能体所带来的回报是递减的 [20]。类似的优势也在使用率失真理论（rate distortion theory）中得到了证明 [8]。

为了研究准确性和带宽之间内在的权衡，特别是以一种相对于智能体数量有界的方式进行扩展，我们提出了一种受通信网络领域中的三次握手（three-way handshaking）启发的三个阶段通信机制 [21]。我们方法的三个步骤是：
1.  **请求（Request）**：受损智能体广播一个以其视觉观测为条件的压缩请求；
2.  **匹配（Match）**：其他智能体计算其自身视觉观测与接收到的请求之间的一个学习到的匹配分数；
3.  **连接（Connect）**：受损智能体选择其中一个智能体进行通信，从而进一步提高其在下游感知任务中的预测准确性。

整个机制以端到端的方式进行训练，仅使用下游任务（例如语义分割）的监督。我们表明，这种通信机制有效地解耦了请求、分数和实际传输的值，允许在此通信过程中使用不同（即非对称）的大小。我们的实验表明，与中心化基线相比，这导致了显著的带宽节省，并且比智能体间的统一压缩获得了更高的准确性增益。为了研究该方法的特性，我们使用 AirSim 模拟器 [34] 开发了 AirSim-CP 数据集和指标，其中一组空中机器人在具有不同景观（如道路、草地、建筑物、湖泊等）的地图上飞行。我们在场景中改变了许多元素，包括它们的轨迹、目标智能体与其他智能体视野之间的部分或完全重叠，以及用于跨视图几何变换（warping）的位姿信息的准确或嘈杂程度。我们定量地表明，我们提出的方法能够比去中心化基线显著提高约 20% 的准确性，并且在使用四分之一带宽的情况下与中心化基线相当。

我们强调本文的贡献如下：
* 我们在多智能体系统、感知、通信和学习的交叉领域提出了一个新的问题。据我们所知，与之前关于学习通信的工作相比，我们是第一个解决在带宽限制下学习通信问题的人。
* 与其他多智能体系统 [14, 17] 不同，我们要收集的数据集 AirSim-CP 提供了高分辨率和照片般逼真的图像，以便更好地评估带有通信的多智能体感知任务。
* 我们提出了一个端到端通信框架，该框架的训练无需指示用于通信的“地面真值智能体”的监督，并且表现出优于去中心化基线的准确性，且仅用一小部分带宽即可与强大的中心化基线相媲美。

---



### II. 相关工作

多智能体环境中的通信是协同感知和决策的基础。这一主题在多智能体强化学习（MARL）领域已被广泛研究 [22, 33, 28]。早期的尝试利用预定义的通信协议在智能体之间传播信息 [37, 39, 27]，而环境的动态性和智能体数量的变化促进了可学习的多智能体通信的发展 [36, 11, 2, 14, 10, 29, 17, 35, 18, 7, 30, 9, 15, 19]。现有的 MARL 工作证明了通信在各种任务中的有效性，将模型应用于简单的 2D 网格环境，其中每个智能体的观测都是低维的。正如 Jain 等人 [15] 所指出的，在简单的环境中研究协作不允许研究感知与通信之间的相互作用。因此，在这项工作中，我们在一个更复杂和照片般逼真的环境中检查我们的框架。

在现有的关于学习通信的工作中，与我们工作最相关的框架是 TarMac [7]，其中目标通信被定义为由发送者和接收者智能体共同确定的传输消息。然而，在通信期间，消息和数据都被广播给所有其他智能体，因此没有考虑带宽使用。另一方面，最近的其他工作提出基于预定义规则 [17, 16] 或统一通信网络 [35, 36, 14, 29, 35, 7] 构建通信组。通过这种方式，通信期间的带宽使用量随着智能体数量的增加而增加。相比之下，我们的框架旨在通过选择与哪个（些）智能体进行通信，在最小化带宽消耗的同时保持感知任务的性能。

---



### III. 提出的方法

#### A. 问题定义与动机

在我们提出的协同感知任务中，环境由 $N$ 个智能体组成，它们拥有各自的观测 $X=\{x_{i}\}_{i=1,...,N}$，而目标智能体 $\tilde{x}_{j}, j\in\{1,...,N\}$ 的观测是受损的。目标智能体的目标是整合从其他智能体接收到的信息，以推导出对其自身局部观测的预测。实际上，通信机制通常有带宽限制，阻止在通信期间传输大量信息。因此，我们的目标是推导出一个分布式的信息融合框架，该框架能够 (1) 最大化目标智能体下游感知任务的预测准确性，以及 (2) 最小化传输期间使用的带宽，如图 1 所示。我们提出的通信框架可以推广到许多感知任务，在本文中，我们将语义分割作为一个实例来评估该框架。

#### B. 通过三阶段握手进行通信

与其以蛮力方式在整个网络中广播所有信息，一种在保持性能的同时最小化带宽使用的有效方法是选择与哪个智能体进行通信。为此，受通信网络相关工作 [21] 的启发，我们引入了图 2 所示的三阶段握手通信机制。这种选择是受率失真理论 [8] 和多重观测的子模性 [20] 的著作启发的。我们的实证实验结果也表明，与对所有智能体的信息进行统一压缩相比，这种方法在带宽使用和性能之间产生了更好的权衡。

我们的通信机制包括三个主要步骤：请求、匹配和连接。具体来说，受损智能体首先将其请求消息 $\mu_{j}\in\mathbb{R}^{m}$ 广播给邻近的正常智能体，正常智能体计算其键（keys） $\kappa_{i}\in\mathbb{R}^{k}$ 与请求消息之间的匹配分数 $s_{ji}$。一旦正常智能体将它们的匹配分数返回给受损智能体，受损智能体根据这些匹配分数进一步选择最佳的 $n$ 个智能体进行连接（即从中接收信息）。完整的通信步骤如图 3 所示。在每个步骤中，信息可以由每个智能体 $i$ 通过键生成器 $G_{k}^{i}$、消息生成器 $G_{m}^{i}$、图像编码器 $E^{i}$ 和任务解码器 $D^{t}$ 进行压缩。请注意，这种方法有效地解耦了各个阶段，允许对消息、键和值使用不同的压缩率。这显著有利于带宽和准确性之间的权衡。我们现在详细介绍这些步骤：

**请求 (Request)**：受损智能体 $j$ 首先将其观测 $\tilde{x}_{j}$ 压缩为一个低维消息 $\mu_{j}$：
$$\mu_{j}=G_{m}^{j}(\tilde{x}_{j};\theta_{m})\in\mathbb{R}^{m} \quad (1)$$
其中 $G_{m}^{j}$ 是由 $\theta_{m}$ 参数化的消息生成器。传播的消息 $\mu_{j}$ 压缩了来自受损智能体 $j$ 局部观测的重要信息。

**匹配 (Match)**：在匹配步骤中，其他每个智能体推导从受损智能体接收到的请求消息 $\mu_{j}$ 与从其自身观测生成的键 $\kappa_{i}$ 之间的匹配分数 $s_{ji}$，
$$s_{ji}=\Phi(\mu_{j},\kappa_{i}), \quad \kappa_{i}=G_{k}^{i}(x_{i};\theta_{k})\in\mathbb{R}^{k}, \quad (2)$$
其中 $\Phi(\cdot,\cdot)$ 表示两个向量的匹配函数，$G_{k}^{i}$ 表示由 $\theta_{k}$ 参数化的键生成器。我们使用通用注意力机制（General Attention） [25] 作为我们的匹配函数：
$$\text{General: } \Phi=\mu_{j}^{T}W_{a}\kappa_{i} \quad (3)$$
其中 $W_{a}$ 是一个可学习的参数。我们还将它与其他两种注意力机制进行了比较：缩放点积（Scale Dot-Product） $\Phi=\mu_{j}^{T}\kappa_{i}/\sqrt{d_{n}}$ [38] 和加性（Additive） $\Phi=W_{a}^{T}\tanh(W_{k}x_{i}+\tilde{W}_{m}\mu_{j})$ [1]，其中 $W_{k}, W_{m}$ 表示待学习的参数，$d_{n}$ 表示消息和键的维度。请注意，只有通用和加性函数允许不同的键和消息大小。缩放点积函数要求消息和键的大小相同。根据经验，我们发现在我们的实验中通用注意力表现最好，因此除非另有说明，否则我们使用它。请注意，我们假设智能体之间的链路成本相等，尽管我们的模型可以进一步支持每条链路的成本（不像基线方法）。我们将此留作未来工作。

**连接 (Connect)**：在连接步骤中，被选中的第 $i$ 个智能体将请求的信息（例如，用于语义分割的特征图）$f_{i}$ 传输给受损智能体。利用整合后的信息，目标受损智能体做出最终预测 $\tilde{y}_{j}$ 如下：
$$\tilde{y}_{j}=D^{j}([\tilde{f}_{j};f_{i}];\theta_{d}) \quad (4)$$
其中 $f_{i}=E^{i}(x_{i};\theta_{e})\in\mathbb{R}^{d_{f}\times d_{f}\times d_{c}}$ 是来自正常智能体 $i$ 的局部观测的特征图，$d_{f}, d_{c}$ 分别是特征图的空间维度和通道数，$\tilde{f}_{j}=E^{j}(\tilde{x}_{j};\theta_{e})$ 是来自受损智能体噪声观测的特征图，$[;]$ 是沿通道维度的拼接操作符。$\theta_{e}$ 和 $\theta_{d}$ 是任务编码器和解码器中的参数。

#### C. 在弱监督下学习通信

**中心化训练与去中心化执行**。我们的学习策略受到中心化训练与去中心化执行概念 [24] 的启发。在训练期间，我们的目标智能体可以访问所有其他智能体的观测。另一方面，在推理期间，目标智能体需要通过仅访问所选智能体的信息来以受限带宽的方式执行。具体而言，在训练期间，任务解码器使用所有正常智能体观测值的总和（由其相应的匹配分数加权），并进一步计算最终预测，类似于推理期间的公式 4：
$$\tilde{y}_{j} = D^{j} ([\tilde{f}_{j}; f_{Sum}]; \theta_d), \quad f_{Sum}=\sum_{i=1}^{N}\alpha_{j,i}f_{i}, \quad (5)$$
其中 $\alpha_{j,i}$ 是 $\alpha_{j}=\rho([s_{j1};...;s_{jN}])\in\mathbb{R}^{N}$ 的第 $i$ 个元素，$\rho$ 是 softmax 操作。最直接的去中心化执行方法是简单地采用 argmax 选择，即仅连接到具有最高计算匹配分数的智能体：
$$i = \text{argmax}_{i} s_{ji} \quad (6)$$
然而，argmax 选择在训练期间是不可微的。我们通过在训练阶段简单地应用 softmax 操作符而在推理阶段应用 argmax 操作符来解决这个问题。根据经验，我们发现这种简单的方法与其他更复杂的方案（例如 sparsemax [26]）相比取得了类似的结果。另外请注意，这也同样可以推广到 top-n 选择。

**训练目标**。学习我们的模型不需要指示与之通信的最佳智能体的地面真值标签的监督。因此，我们模型的唯一监督来自目标视图处的地面真值标注（例如，分割掩码）。我们模型的（端到端训练的）目标函数因此可以定义为 $\mathcal{L}=\mathcal{H}(y_{j},\tilde{y}_{j})$，其中 $\mathcal{H}$ 是交叉熵损失，$y_{j}$ 表示目标智能体视图的地面真值标签。

---



### IV. 实验结果

#### A. AirSim-CP 数据集

**数据集**。我们的 AirSim-CP 数据集建立在 AirSim 模拟器 [34] 之上，其中一组五架无人机在具有不同景观（如道路、草地、建筑物、湖泊等）的地图上飞行。目前，在我们的 AirSim-CP 数据集中，我们使用语义分割作为下游任务来基准测试协同感知问题的方法。对于每架无人机，都会记录 RGB 图像、深度图像和位姿。我们还提供其中一个智能体的语义分割掩码。

#### B. 提出的实验设置

如图 4 所示，为了获得真实轨迹下的感知数据，无人机执行预指定的航点跟随（waypoint following）和多智能体随机探索（random exploration）任务。然后我们考虑四种实验设置：(1) 隐藏目标视图（航点跟随轨迹），(2-3) 准确或不准确的位姿（航点跟随轨迹），以及 (4) 准确位姿（随机探索轨迹）。我们为每个设置收集大约 10-20k 张图像，训练/验证/测试的划分比例大致为 60%/20%/20%。在所有情况下，都有一个受损的目标智能体。我们通过应用随机大小（从 1 到 100）的高斯模糊滤波器和高斯噪声来扰动目标智能体的视图。在指定时，使用深度和位姿信息将正常智能体的视图变换（warp）到目标视图。在优化方面，我们使用 ResNet18 [13] 作为特征骨干网络，并使用学习率为 $10^{-5}$ 的 Adam 优化器对其进行 200k 次迭代训练。

**具有多智能体航点跟随的隐藏目标视图**。智能体被要求在航点之间导航，但在执行语义分割任务时，我们不是让所有的邻近智能体都作为正常智能体，而是将其中的一个正常智能体替换为目标视图的未受损版本。此任务测试基线和提出的方法能否帮助目标智能体在邻近智能体中找到隐藏的地面真值目标视图。因此，该实验可以被视为对通信的健全性检查（sanity check）。请注意，我们不使用任何 3D 信息将正常视图变换到目标视图。这种情况的动机是从协同感知任务的研究中消除几何变换和图像未对齐（这对语义分割任务很重要 [31]）的混淆。我们的重点是确保通信能够在带宽受限的方式下有效且准确。因此，我们可以从这个案例中直接评估通信的有效性。

**具有多智能体航点跟随的准确位姿**。与之前的设置类似，五架无人机联合执行航点跟随。不同的是，目标智能体的视野（FOV）仅与部分正常智能体子集重叠。这种情况旨在测试提出的方法是否可以选择具有部分重叠 FOV 的正常智能体，以辅助下游感知任务。为了保持图像对齐以获得更好的分割预测，我们使用来自每个正常智能体视图的深度图的 3D 信息和相对于目标视图的准确位姿变换，将正常智能体观测的像素变换到目标视图。请注意，深度图不需要传输（变换在每个智能体上本地完成），但我们将目标位姿传输到其他智能体计入使用的带宽中，尽管它很小。

**具有多智能体航点跟随的不准确位姿**。为了进一步使我们的实验设置更加逼真，我们在智能体的位置中添加了噪声。这导致变换后的图像与目标视图无法很好地对齐。

**具有多智能体随机探索的准确位姿**。我们还研究了多智能体随机探索期间的协同感知，其中智能体接近目标位置，分散并游荡。随着智能体单独探索环境，智能体的相对位置和重叠视野经常变化。

#### C. 基线

我们考虑以下方法进行比较：
* **Single normal（上限）**和 **Single degraded（下限）**：模型分别使用目标智能体的单张未受损和受损图像进行训练。
* **CatAll（中心化）**：该模型使用来自受损和正常智能体的所有特征的拼接作为语义分割的输入。
* **Attention（中心化）**：Attention 机制对特征图进行加权和求和，而不是像 CatAll 方法那样进行拼接。
* **Compression（中心化）**：压缩模型应用两个额外的卷积层，并以 25% 的比率对所有观测结果执行统一压缩，使用拼接来组合它们。请注意，我们当然可以用更复杂的压缩编码器替换我们的图像编码器，以进一步提高压缩率 [5]。
* **Random selection（分布式）**：这里不是学习选择与哪个智能体进行通信，而是选择来自随机正常智能体的特征图。
* **Ours（分布式）**：我们将我们提出的方法表示为“ours with message (ours w/ msg)”，以及另一种变体，其中消息请求 $\mu_{j}$ 被设置为一个全为 1 的常量向量，以检查消息请求是否必不可少。值得注意的是，我们在训练期间不使用任何指示最佳智能体的标签。

CatAll 和 Attention 都要求将所有来自正常智能体的特征图发送到受损智能体。中心化基线的带宽随系统中智能体的数量线性扩展，而随机选择和我们的方法只需要传输单个图像特征图。

#### D. 评估指标

为了评估和分析模型的有效性，我们使用 1) 总体准确率（Overall Accuracy）来衡量语义分割的性能 [23]，以及 2) 每帧千字节数（kbpf）来衡量带宽使用（BW），以检查通信和选择的能力。此外，为了更好地基准测试受限带宽下协同感知任务的性能，我们引入了带宽改进分数（Bandwidth-Improvement Score, BIS），定义为：
$$BIS=\frac{\delta-\overline{\delta}}{(\hat{\delta}-\overline{\delta})\omega}, \quad (7)$$
其中 $\delta$ 是被检查方法的总体准确率，$\overline{\delta}$ 是单个受损模型的总体准确率（即总体准确率的下限），$\hat{\delta}$ 是单个正常模型的总体准确率（即总体准确率的上限），$\omega$ 是被检查方法的带宽使用量（以每帧兆字节为单位）。BIS 分数定义为总体准确率的相对提高与带宽使用的比率。较小的带宽使用和较大的总体准确率提高会导致较高的分数。

---

### V. 结果与消融实验

在本节中，我们在四种情况下（第 IV-B 节）比较了我们提出的方法与基线，如表 I 所示。

**具有多智能体航点跟随的隐藏目标视图**。如前所述，此情况不应用几何变换。这导致了对通信的更好评估，因为消除了目标视图的变换噪声，且未变换的正常图像使得选择更加困难。从这个案例中可以得出几个观察结果。首先，由于中心化基线能够访问来自不同视图的所有观测结果，它们应该是包括我们提出的模型在内的所有分布式方法的上限。然而，我们发现我们的模型相对于 CatAll 将总体准确率提高了 16.51%，且仅使用了四分之一的带宽。这表明简单地拼接所有信息并不能保证网络会有意义地组合它们，并且带宽可能会被浪费。其次，为了预测逐像素输出并准确预测细粒度类别，场景理解任务在推理期间需要高维特征图。使用过度压缩的特征图可能会降低总体准确率，因此我们的带有消息的模型相对于 Compression 模型可以将总体准确率提高 20.06%。最后，我们还观察到，与没有消息相比，我们带有消息的模型可以将 mIoU 提高 29.49%。这证明了通信中消息的必要性。

**具有多智能体航点跟随的准确和不准确位姿**。这些情况的一个挑战是目标和正常智能体之间的视野部分重叠。通过对正常智能体的视觉观测进行前向几何变换，我们观察到只有一个或两个智能体包含目标视图的部分信息。因此，与之前的任务相比，分布式模型的性能有所下降。我们的模型仍然能够获得与中心化方法类似的结果，仅使用四分之一的带宽，并且仍然在这些方法中获得最高的 BIS。值得注意的是，我们带有和不带有消息的模型表现相似，因为模型可以依赖来自正常智能体图像的变换线索（例如，重叠量），从而减少了对消息条件的依赖。另外请注意，虽然由于位姿不准确导致 BIS 有所下降，但它仍然能够显著击败基线。

**具有多智能体随机探索的准确位姿**。虽然在这种情况下重叠的 FOV 和智能体的运动经常变化，但我们观察到我们的模型与其他基线方法相比仍然表现良好。这表明我们的模型在不同环境和任务中具有鲁棒性。

**消息和键的大小**。为了更好地检查智能体选择的准确性，我们手动标注了隐藏目标视图测试集的“最佳”智能体，并进一步测量了各种模型的选择准确性和总体准确性。当使用通用注意力时，消息和键的大小可以设置为不同的值。我们首先通过将消息大小从 1 变化到 64 来分析消息大小的影响，如图 5a 所示。我们观察到较大的消息大小会导致选择准确性和分割质量的提高。请注意，大小为 4 的消息足以在选择和分割上获得可比较的性能，此后性能趋于平稳。我们还通过将键大小从 4 变化到 1024 进行了类似的实验，在图 5b 中可以观察到相同的趋势。此外，我们根据经验发现，小消息（例如 8）搭配大键尺寸（例如 1024）可以实现令人满意的性能。这也是我们第 V 节所有实验的模型大小。重要的是，非对称大小的有效性是一个有趣的发现，因为它允许我们使用较小的消息大小发送给其他智能体，同时使用较大的键大小由每个智能体本地计算分数（因此不需要传输）。这些结果验证了这一优势。

---

### VI. 结论

在本文中，我们制定了协同感知问题，其中智能体可以将其局部观测与其他智能体的观测相结合，以提高场景理解任务的性能。受网络通信文献的启发，我们提出了一种握手通信机制，网络可以通过该机制学习压缩表示。我们方法的关键是我们解耦了消息、键和值元素以支持非对称压缩，从而节省带宽。我们引入了 AirSim-CP 数据集和基准指标来评估我们的方法，并表明我们的方法能够有效地结合来自邻近智能体的信息以提高准确性，同时使用的带宽显著少于中心化方法。

---

