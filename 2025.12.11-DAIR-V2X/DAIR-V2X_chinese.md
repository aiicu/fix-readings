DAIR-V2X：用于车路协同自动驾驶的大规模数据集



### 摘要

自动驾驶面临着巨大的安全挑战，因为它缺乏全局视角和远距离感知能力的限制。人们普遍认为，实现 L5 级自动驾驶需要车路协同。然而，目前计算机视觉研究人员仍没有可用于解决车路协同相关问题的真实场景数据集。为了加速计算机视觉研究和车辆基础设施协同自动驾驶（VICAD）的创新，我们发布了 DAIR-V2X 数据集，这是第一个用于 VICAD 的、来自真实场景的大规模、多模态、多视角数据集。DAIR-V2X 包含 71254 帧 LiDAR 帧和 71254 帧 Camera 帧，所有帧均来自真实场景并带有 3D 标注。我们引入了车辆基础设施协同 3D 目标检测问题（VIC3D），它提出了一个利用来自车辆和基础设施的传感器输入，协同定位和识别 3D 目标的问题。除了解决传统的 3D 目标检测问题之外，VIC3D 的解决方案还需要考虑车辆和基础设施传感器之间的时间异步问题以及它们之间的数据传输成本。此外，我们提出了时间补偿晚期融合（TCLF）框架，作为基于 DAIR-V2X 的 VIC3D 任务基准测试。



### 1. 简介

自动驾驶（AD）无疑是目前最受公众关注和想象的主题之一。深度神经网络的成功带来了解决 AD 核心要求——从点云、图像或多模态数据感知周围环境的希望。尽管最近取得了巨大进步，但由于缺乏全局视角和远距离感知能力的限制，自动驾驶仍面临巨大的安全挑战。人们普遍认为，实现 L5 级自动驾驶需要车路协同。利用车辆和基础设施传感器带来了许多显著的优势，包括提供超出当前视野的全局视角和覆盖盲区。V2X（车对万物）等通信技术的进步使得利用来自基础设施传感器的数据成为可能。然而，目前研究人员仍没有可用于解决车路协同相关问题的真实场景数据集。为了加速计算机视觉研究和车辆基础设施协同自动驾驶（VICAD）的创新，我们发布了 DAIR-V2X 数据集，这是第一个用于 VICAD 的、大规模、多模态、多视角数据集。它包含 71254 帧 LiDAR 帧和 71254 帧 Camera 帧，这些帧是在部署了基础设施传感器的交叉路口场景中捕获的，其中一辆装备精良的车辆穿过这些交叉路口。其中 40% 的帧由基础设施传感器捕获，60% 的帧由车辆传感器捕获。所有帧都经过专家标注员的精确标注。该数据集涵盖了 10 公里的城市道路、10 公里的高速公路、28 个交叉路口和 38 平方公里的驾驶区域，具有不同的天气和光照变化。

在本文中，我们引入了车辆基础设施协同 3D 目标检测（VIC3D）任务，它提出了一个利用来自车辆和基础设施的传感器输入，协同定位和识别 3D 目标的问题。除了解决传统的 3D 目标检测问题之外，VIC3D 的解决方案还需要考虑车辆和基础设施传感器之间的时间异步问题和数据传输成本。为了解决 VIC3D 目标检测任务并促进未来研究，我们还在本文中介绍了我们的 VIC3D 目标检测基准。对于时间异步问题较少的数据，我们实施了早期融合和晚期融合方法。结果表明，融合方法的平均精度比仅使用单一视角信息的检测器高出 10 到 20 个百分点。结果还表明，早期融合可以实现比晚期融合更好的性能，但需要更多的数据传输。我们期望通过 DAIR-V2X 数据集，未来能有更多的研究来实现性能-带宽的权衡。对于时间异步问题严重的数据，我们提出了时间补偿晚期融合框架，可以有效地缓解时间异步问题。

我们工作的主要贡献如下：

- 我们发布了 DAIR-V2X 数据集，这是第一个用于车路协同自动驾驶的大规模数据集。所有帧均来自真实场景并带有 3D 标注。
- 我们提出了 VIC3D，将利用来自车辆和基础设施的传感器输入，协同定位和识别 3D 目标的问题形式化。
- 我们引入了 VIC3D 目标检测和单视角 3D 目标检测任务的基准。结果表明了车路协同在 VIC3D 目标检测中的有效性。特别是，我们提出了时间补偿晚期融合框架来缓解时间异步问题。



### 2. 相关工作

#### 2.1. 自动驾驶数据集

近年来，越来越多的自动驾驶数据集发布，极大地促进了自动驾驶研究的发展。像 SYNTHIA 和 Cityscapes 这样的数据集主要关注图像的 2D 标注。KITTI 和 nuScenes 是多模态数据集，提供了相机图像以及 LiDAR 点云。然而，上面提到的所有数据集都只提供了来自单车视角的数据。V2X-SIM 是生成多车视角数据集的尝试，但该数据集是通过模拟器生成的，而不是从真实场景中捕获的。与这些数据集相比，我们的 DAIR-V2X 数据集是第一个用于 VICAD 的、从真实场景中捕获的大规模、多模态、多视角数据集，并且包含从车路协同视角捕获的数据。

在我们的 DAIR-V2X 中，我们还提供了一个 Repo3D 数据集，由多源基础设施图像和 3D 标注组成，供对 Mono3D 目标检测和域适应感兴趣的人使用。



#### 2.2. 3D 检测

3D 目标检测是自动驾驶成功的先决条件。已经引入了许多技术，大致可以分为三类。

a) 基于图像的 3D 检测指的是直接从 2D 图像检测 3D 目标的方法。ImVoxelNet 是一个很好的例子，可以从图像进行预测。

b) 基于点云的 3D 检测指的是仅从点云进行 3D 目标检测的方式。PointPillars、SECOND 和 3DSSD 是从点云中获得令人信服的检测结果的方法。

c) 基于多模态的 3D 检测使用图像和点云进行预测。PointPainting 和 MVXNet 是融合图像和 LiDAR 特征来预测 3D 边界框的实践。

尽管 3D 目标检测最近取得了巨大进展，但仍有一些棘手的问题需要解决，例如盲区和弱远距离感知。为了探索如何利用基础设施信息来解决上述问题，我们基于本文提出的数据集进行 VIC3D 目标检测。



#### 2.3. 多传感器融合

多传感器融合是集成不同传感器收集的异构信息，以减轻依赖单一传感器系统的_不确定性_和_脆弱性_。根据融合阶段，多传感器融合可以分为早期融合、中间融合和晚期融合。

a) 在早期融合中，来自不同传感器的原始数据被直接传输和融合。

b) 在中间融合中，融合从模型中提取的特征等中间表示。

c) 在晚期融合中，融合预测输出，如目标的 3D 信息。

VIC3D 可以被认为是多传感器问题的变体，因此可以考虑使用以前的融合方法来整合基础设施信息。然而，除了多传感器融合挑战之外，VIC3D 还面临着时间异步问题和数据传输约束带来的困难。



#### 2.4. V2X 协同感知

V2X 旨在在复杂的交通环境中建立车辆与其他设备之间的通信系统。当前的 V2X 研究主要集中在 V2V（车对车）和 V2I（车对基础设施）领域。V2VNet 是 V2V 领域的开创性工作，它广播压缩的中间特征，并传播从附近车辆接收到的消息以生成运动预测。V2I 的工作利用基础设施 LiDAR 数据生成并广播检测结果。然而，这些方法都没有在从真实场景捕获的数据集上得到验证。这可能会导致理论与实践之间的巨大差距。因此，我们发布了 DAIR-V2X 数据集，以促进该领域的进一步研究。



### 3. DAIR-V2X 数据集

为了促进 VICAD 的研究，我们发布了 DAIR-V2X，这是一个来自真实场景的、带有 3D 标注的、用于车路协同的大规模、多模态、多视角数据集。在这里，我们描述了我们如何设置基础设施和车辆传感器、选择有趣的场景、标注数据集以及保护第三方隐私。



#### 3.1. 设置

**设备**。数据采集设备由基础设施传感器和车辆传感器组成。

a) **基础设施传感器**。从北京高级别自动驾驶示范区选取的 28 个交叉路口中的每一个都部署了四对 300 线束 LiDAR 和高分辨率相机。DAIR-V2X 数据集只选取了其中的一对。

b) **车辆传感器**。一辆 40 线束 LiDAR 和一个向前看的高质量相机安装在自动驾驶车辆的顶部。具体的布局发布在图 2 中，详细的细节显示在表 2 中。

| **Sensor**     | **Details**                                                  |
| -------------- | ------------------------------------------------------------ |
| Inf. LiDAR     | 300 beams, 10Hz capture frequency, $100^{\circ}$ horizontal FOV, $-30^{\circ}$ to $10^{\circ}$ vertical FOV. $\le 280m$ range. $\pm 3cm$ accuracy |
| Inf. Camera    | RGB, 25Hz capture frequency, 1920x1080 resolution, JPEG compressed |
| Veh. LiDAR     | 40 beams, 10Hz capture frequency, $360^{\circ}$ horizontal FOV, $-30^{\circ}$ to $10^{\circ}$ vertical FOV. $\le 200m$ range, $\pm 0.33^{\circ}$ vertical resolution |
| Veh. Camera    | RGB, 20Hz capture frequency, 1920x1080 resolution, JPEG compressed |
| Veh. GPS & IMU | 1000HZ update rate                                           |

**坐标**。DAIR-V2X 上有 5 种坐标系，即 LiDAR 坐标、相机坐标、图像坐标、世界坐标和定位坐标。LiDAR 坐标系的原点位于 LiDAR 传感器的中心，x 轴正向向前，y 轴正向向左，z 轴正向向上。基础设施 LiDAR 坐标系从其原始系统转换而来，该原始系统与地面有一个倾角。装备车辆的实时相对姿态是通过 GPS/IMU 结合 SLAM 和本地地图获得的。还有手动二次标注确认以确保校准精度。Lidar 到 Camera 的变换是通过将 Lidar 到 World 和 World 到 Camera 的变换相乘得到的。



#### 3.2. 数据采集

**采集**。我们驾驶一辆装备精良的车辆在采集区域内，并分别保存相应的车辆帧和基础设施帧。在原始数据采集后，我们手动选择了 100 个具有代表性的 20 秒时长的场景。这些场景包括车辆数据和基础设施数据，其中车辆穿过部署了设备的交叉路口。我们从两侧以 10Hz 采样关键帧，形成 DAIR-V2X-C。在 DAIR-V2X-C 中，重要的是要注意，由于车辆传感器和基础设施传感器之间的异步触发，车辆帧与其最近的基础设施帧之间的时间戳差异可能会略有不同。我们从额外的大约 350 个 60 秒时长的仅车辆片段中采样了 22K 帧，形成 DAIR-V2X-V，并从额外的大约 150 个仅基础设施片段中采样了 10K 帧，形成 DAIR-V2X-I，以扩大数据集。与 DAIR-V2X-C 中的单视角数据相比，DAIR-V2X-V 和 DAIR-V2X-I 包含更多样化的场景，并且对于仅提高单视角性能将更具挑战性。

**标注**。经过多次验证步骤和细化过程，专家标注员分别对基础设施帧和车辆帧进行了高质量标注。具体来说，标注员详尽地标注了每个图像和点云帧中的 10 个目标类别，包括其类别属性、遮挡状态、截断状态以及一个 7 维长方体，建模为 x、y、z、宽度、长度、高度和偏航角。10 个类别包括不同的车辆、行人、不同的骑自行车者。此外，专家还仔细地用矩形边界框（建模为 x、y、宽度和长度）标注了相机图像中的目标。值得一提的是，我们还对带有车辆和基础设施帧对的协同标注进行了半自动标注。我们首先从 DAIR-V2X-C 中选择车辆和基础设施帧对。所选帧对之间的时间戳差异小于 10 毫秒（我们称之为同步情况，在第 4.1 节中定义。为了获得更多的协同标注，我们将阈值从 10 毫秒扩展到 30 毫秒）。接下来，我们将基础设施 3D 框转换到车辆 LiDAR 坐标系中，并融合车辆标注和基础设施标注。对于基础设施标注中的每个 3D 框，如果我们在车辆标注中找不到任何具有相同位置和类别的 3D 框，我们则将该基础设施 3D 框添加到车辆标注中；通过这种方式，我们获得了车路协同标注。我们手动监督和调整协同标注以生成更准确的标注。在这里，我们选取 9331 帧基础设施帧和车辆帧以及协同标注，形成 VIC-Sync 数据集，用于我们的 VIC3D 目标检测基准。

**保护**。整个数据集在公开发布之前进行了脱敏处理。根据当地法律法规，我们删除了所有定位信息，包括道路名称、地图数据和定位信息，以确保我们的数据集符合要求。此外，我们利用专业的标注工具对所有涉嫌侵犯隐私的信息进行模糊处理，包括路标、车牌和人脸，以保护隐私并避免侵犯个人权利。



### 4. 任务与指标

自动驾驶面临着巨大的安全挑战，因为它缺乏全局视角和远距离感知能力的限制。由于 3D 目标检测是自动驾驶中的关键感知任务之一，在本文中，我们关注车辆基础设施协同（VIC）3D 目标检测任务，即车辆接收并整合来自基础设施的信息，以定位和识别周围的目标。与传统的多传感器 3D 目标检测任务相比，VIC3D 目标检测具有以下不同的特点：

- **传输成本**。受限于物理通信条件，应从基础设施传输更少的数据，以减少带宽消耗、减轻时间延迟并满足实时性要求。因此，VIC3D 目标检测的解决方案需要在性能和传输成本之间进行权衡。
- **时间异步**。由于异步触发和传输成本造成的时间延迟，车辆传感器和基础设施传感器的数据时间戳是不同的，这会产生时空误差。因此，在解决 VIC3D 时应考虑时间同步。

为了更好地形式化 VIC3D 目标检测任务，我们将在本节中给出 VIC3D 目标检测的详细定义，然后提供两个指标来衡量检测性能和传输成本。



#### 4.1. VIC3D 目标检测

VIC3D 目标检测可以形式化为有效整合基础设施和车辆信息以定位和识别 3D 目标，并考虑传输成本的优化问题。在这里，我们讨论 VIC3D 的输入和输出应该是什么。

**输入**。VIC3D 的输入由来自车辆和基础设施的数据组成。

- **车辆帧** $I_{v}(t_{v})$：在时间 $t_{v}$ 捕获，以及其相对姿态 $M_{v}(t_{v})$，其中 $I_{v}(\cdot)$ 表示车辆传感器的捕获函数。
- **基础设施帧** $I_{i}(t_{i})$：在时间 $t_{i}$ 捕获，以及其相对姿态 $M_{v}(t_{i})$，其中 $I_{i}(\cdot)$ 表示基础设施传感器的捕获函数。

注意 $t_{i}$ 应该早于 $t_{v}$，因为数据从基础设施传输到车辆会产生时间延迟。考虑到目标在极小的时间间隔内移动非常轻微，空间偏移可以忽略不计，我们把 $|t_{v}-t_{i}|\le10ms$ 的情况作为**同步情况**（即 $t_{v}\approx t_{i}$）。类似地，我们把 $|t_{v}-t_{i}|>10ms$ 的情况作为**异步情况**。此外，我们允许在解决 VIC3D 时使用早于 $I_{i}(t_{i})$ 的更多基础设施帧，以充分利用基础设施计算资源。

**真值**。VIC3D 目标检测的输出包含围绕车辆的目标的 3D 信息，如位置、类别和方向。VIC3D 的相应真值是基础设施和车辆真值的融合结果，可以形式化为：
$$
GT=GT_{v}\cup GT_{i} \label{eq:1}
$$
其中 $GT_{v}$ 是车辆传感器感知的真值， $GT_{i}$ 是基础设施传感器感知的真值。

VIC3D 主要用于提高自驾车的感知性能。我们更关注自我中心周围的某个范围内的目标以及目标在时间 $t_{v}$ 的 3D 信息，而不是在 $t_{i}$ 的 3D 信息。因此，$GT_{v}$ 和 $GT_{i}$ 都应该基于时间 $t_{v}$。然而，从基础设施和车辆捕获的输入帧的时间戳可能不同，即 $t_{v}\ne t_{i}$。这不仅给模型预测中融合基础设施信息带来了挑战，也给生成真值带来了巨大问题。这是因为用时间 $t_{i}$ 的基础设施帧标注的目标在时间 $t_{v}$ 可能会移动到不同的位置，而且我们无法直接获得时间 $t_{v}$ 的基础设施帧进行标注。针对这些困难，我们讨论了如何基于 DAIR-V2X 生成 VIC3D 的真值。

- **同步情况**（即 $t_{v}\approx t_{i}$）。在此条件下，出现在车辆帧 $I_{v}(t_{v})$ 中的目标应与出现在基础设施帧 $I_{i}(t_{i})$ 中的目标具有相同的空间位置。因此，我们可以直接将第 3.2 节中所示的通过半自动标注获得的_车路协同 3D 标注_作为真值。
- **异步情况**（即 $t_{v}\ne t_{i}$）。如果我们可以找到满足 $|t_{v}-t_{i}|\le10ms$ 的基础设施帧 $I_{i}(t_{i}')$，我们可以使用 $I_{i}(t_{i}')$ 生成真值。如果找不到，我们必须估计目标在 $t_{v}$ 时的 3D 状态来生成真值。在我们在未来工作中提供跟踪 ID 后，这项工作可以基于跟踪 ID 和运动学方程进行。



#### 4.2. 评估指标

VIC3D 目标检测有两个主要目标：更好的检测性能和更低的传输成本。我们描述了衡量这两个目标的指标如下。

**平均精度**。AP（平均精度）是衡量目标检测器性能的常用指标。我们也使用 AP 来评估以协同标注为真值的 3D 检测性能。由于我们更关注自我中心周围的环境，我们移除了设计区域外的目标。在这里，我们将设计区域设置为矩形区域 $[0, -39.12, 100, 39.12]$。

**传输成本**。我们使用 AB（平均字节数）来衡量传输成本。这里的字节是一个数字信息单位，由八位组成。为了简化问题，我们忽略了传输过程中数据编码器和解码器的时间消耗。这意味着传输成本越低，时间延迟越短。要从基础设施传输的数据可以是以下形式之一或其组合。

- 像图像或点云这样的**原始数据**包含完整的信息，但需要很高的传输成本。
- **中间表示**需要较少的传输成本，同时保留有价值的信息，这可能会实现更好的性能-传输权衡。当然，这需要更复杂的设计来提取合适的中间表示。
- **目标级输出**直接提供 3D 目标信息。虽然传输效率高，但可能会丢失有价值的信息。
- 像**场景流**等其他辅助信息有助于缓解时间异步问题。



### 5. 基准

在本节中，我们在 DAIR-V2X 数据集上提供了 VIC3D 目标检测基准和单视角（SV）3D 目标检测基准，分析了它们的特点并提出了未来研究的途径。



#### 5.1. VIC3D 目标检测基准

我们在从 DAIR-V2X-C 中提取的 VIC-Sync 数据集上提供了 VIC3D 目标检测基准，如第 3.2 节所示。该数据集由 9311 对基础设施帧和车辆帧以及它们的协同标注作为真值组成。此外，我们在基准中考虑了基础设施帧和车辆帧之间的时间异步，这主要是由采样率和传输延迟的差异引起的。为了模拟时间异步现象，我们将 VIC-Sync 数据集中的每个基础设施帧替换为其原始基础设施帧之前的第 k 帧，以构建 VIC-Async-k 数据集进行基准测试。在我们的实验中，我们设置 $k=1, 2$。我们将 VIC-Sync 和 VIC-Async-k 数据集按 5:2:3 的比例划分为训练/验证/测试部分。我们使用协同标注来评估车辆自我中心视角下的检测结果。实验结果呈现在表 3 中。



##### 5.1.1. 基线

在这里，我们介绍了 VIC3D 目标检测的几种具有不同模态和融合方法的基线。

**使用晚期融合的 LiDAR 检测基线**。为了证明通过利用基础设施和车辆数据带来的性能提升，我们实现了一个带有基础设施检测器和车辆检测器的晚期融合框架。首先，我们选择 PointPillars 作为 3D 检测器，并分别使用 VIC-Sync 中的基础设施视角和车辆视角数据训练这两个检测器。然后，我们将基础设施预测结果转换到车辆 LiDAR 坐标系中，并使用基于欧几里得距离测量和匈牙利方法的匹配器合并预测结果，以生成融合结果。为了说明时间异步问题，我们还在 VIC-Async-k 数据集上实现了 LiDAR 检测晚期融合基线。此外，基于跟踪和状态估计，我们提出了**时间补偿晚期融合（TCLF）**框架。TCLF 主要由以下三部分组成：1) 使用两个相邻基础设施帧估计目标的速度。2) 估计基础设施目标在 $t_{v}$ 时的_状态_。3) 按照 LiDAR 晚期融合基线的方式融合估计的基础设施预测和车辆预测。

请注意，我们还报告了仅使用基础设施数据和仅使用车辆数据的评估结果，分别命名为 *Veh.-Only* 和 *Inf.-Only*。评估结果呈现在表 3 中。

**使用晚期融合的图像检测基线**。为了检验仅图像的 VIC3D 目标检测，我们也实现了仅使用基础设施图像和车辆图像的晚期融合框架。我们选择 ImvoxelNet 作为 3D 检测器，并分别使用 VIC-Sync 训练数据中的相应部分训练基础设施检测器和车辆检测器。我们按照 LiDAR 检测晚期融合的方式实现了图像检测晚期融合。

**使用早期融合的 LiDAR 检测基线**。为了探索原始数据级别的融合效果，我们在 VIC-Sync 数据集上实现了以 PointPillars 作为 3D 检测器的早期融合。我们首先将 VIC-Sync 数据集中的基础设施点云转换到车辆 LiDAR 坐标系中，然后融合基础设施点云和车辆点云。我们直接使用融合的点云训练和评估检测器。为了进一步说明时间异步问题，我们还在 VIC-Async-k 数据集上实现了以 PointPillars 作为 3D 检测器的早期融合。



##### 5.1.2. 分析

在这里，我们分析了第 5.1.1 节中 VIC3D 目标检测基准方法的特性。

**协同视角 vs. 单视角**。我们比较了使用和不使用基础设施数据和车辆数据的方法的性能。在表 3 中，晚期融合的检测性能明显优于 Veh.-Only 或 Inf.-Only 的性能，无论是基于图像还是基于 LiDAR，无论是基于 VIC-Sync 数据集还是 VIC-Async-k 数据集。例如，在 VIC-Sync 数据集上，使用晚期融合的 LiDAR 检测实现了 3D 检测的总体 41.90 AP 点和 BEV 检测的总体 47.96 AP 点。然而，仅使用车辆数据的 LiDAR 检测仅实现了 3D 检测的总体 31.33% AP 和 BEV 检测的总体 35.06% AP，而仅使用基础设施数据的 LiDAR 检测仅实现了 3D 检测的总体 17.62% AP 和 BEV 检测的总体 24.40% AP。实验结果表明，融合基础设施信息可以有效地提高车辆的感知性能。这主要是因为基础设施数据提供了补充信息，弥补了车辆的感知视野。

**时间异步 vs. 时间补偿**。时间异步给融合基础设施数据带来了挑战。与 VIC-Sync 数据集上的结果相比，使用融合的 LiDAR 检测在 VIC-Async-k 上的性能显著下降（VIC-Async-1 下降 2 个百分点，VIC-Async-2 下降 6 个百分点）。下降主要是由于移动目标的状态变化，导致匹配困难和融合错误。然而，我们的 TCLF 可以有效地将晚期融合的性能提高，在 VIC-Async-1 上提高高达 0.5% AP，在 VIC-Async-2 上提高高达 1.5% AP，这表明时间补偿可以有效地缓解时间异步问题，尤其是在时间延迟较大时。

**早期融合 vs. 晚期融合**。与晚期融合相比，早期融合在 BEV 和 3D 基准上都实现了高达 8% AP 的提高，无论是基于 VIC-Sync 数据集还是 VIC-Async-1 数据集。然而，早期融合必须传输整个点云，并承受极高的传输成本，这比晚期融合高出约 4000 倍。对于更实际的应用，我们鼓励未来的研究在消耗更少传输带宽的同时实现更好的性能。我们还将在未来发布特征融合的基准。



#### 5.2. SV3D 检测基准

我们为那些对基于 DAIR-V2X-V 和 DAIR-V2X-I 数据集的单视角（SV）3D 检测任务感兴趣的人提供了广泛的 3D 检测基准。与 DAIR-V2X-C 中的单侧数据相比，这两个数据集更加多样化，对实施 3D 目标检测可能更具挑战性。因此，我们鼓励那些旨在提高 DAIR-V2X-V 和 DAIR-V2X-I 上车辆 3D 目标检测或基础设施 3D 目标性能的研究人员。我们将 DAIR-V2X-V 和 DAIR-V2X-I 数据集按 5:2:3 的比例划分为训练/验证/测试部分。我们分别在这两个数据集上展示了基于不同模态方法的多种基线：ImvoxelNet、PointPillars、SECOND 和 MVXNet。我们使用 PASCAL 标准评估 3D 目标检测性能，就像 KITTI 一样，根据图像平面中边界框的高度过滤掉远距离目标。使用三种模式进行评估，包括 Easy、Moderate 和 Hard 模式。我们使用 MMDetection3D 框架实现了这些基线。评估结果如表 4 和表 5 所示。



### 6. 结论

在本文中，我们介绍了 DAIR-V2X，这是第一个用于车路协同自动驾驶的大规模、多模态、多视角数据集，所有帧均来自真实场景并带有 3D 标注。我们还定义了 VIC3D 目标检测，以形式化利用来自车辆和基础设施的传感器输入，协同定位和识别 3D 目标的问题。除了解决传统的 3D 目标检测问题之外，VIC3D 的解决方案还需要考虑车辆和基础设施传感器之间的时间异步问题以及它们之间的数据传输成本。为了促进未来的研究，我们提供了 VIC3D 检测模型的基准，包括我们提出的时间补偿晚期融合框架，以及车辆视角和基础设施视角数据集上的广泛 3D 检测基准。结果表明，整合来自基础设施传感器的数据比单车 3D 检测平均提高 15% AP，并且 TCLF 可以缓解时间异步问题。



### 致谢

我们感谢来自百度公司的 Fan Yang、Ruiwen Zhang、Wenyue Wu 和 Xiao Wang 在数据处理方面的支持。我们感谢 Jilei Mao、Taohua Zhou、Yingjuan Tang、Zan Mao 和 Zhiwen Yang 在基准构建方面的支持。感谢北京高级别自动驾驶示范区、北京车网互联技术有限公司、百度 Apollo 和北京智源人工智能研究院在整个数据集构建和发布过程中的支持。